{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient coding of natural images with a population of noisy Linear-Nonlinear neurons\n",
    "\n",
    "The following is an implementation of Karklin & Simoncelli's 2011 paper, with a model of the visual system maximizing mutual information, minimizing spiking with natural images as input. It is implemented in Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:\n",
    "![fig1](./img/fig1a.png)\n",
    "\n",
    "\n",
    "### Response Function:\n",
    "$$ r_j = f_j(y_j)+n_r $$  \n",
    "\n",
    "$$ y_j = \\textbf{w}_j^T(x+n_x) $$\n",
    "\n",
    "Add indepenent (for now - Pratik will explore non iid) noise in our response, also add noise in our input image, before calcuating non-linear function.\n",
    "\n",
    "### Objective Function:\n",
    "$$ I(X;R) - \\sum_j \\lambda_j \\langle r_j \\rangle $$  \n",
    "\n",
    "Maximize mutual information between image and response, minimizing spiking rate of all neurons. $\\lambda$ as the tradeoff between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x110b2cd68>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dda/anaconda/envs/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 140, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/dda/anaconda/envs/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 905, in close\n",
      "    self._default_session.__exit__(None, None, None)\n",
      "  File \"/Users/dda/anaconda/envs/tensorflow/lib/python3.4/contextlib.py\", line 66, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/Users/dda/anaconda/envs/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 3215, in get_controller\n",
      "    assert self.stack[-1] is default\n",
      "AssertionError: \n"
     ]
    }
   ],
   "source": [
    "#dependencies\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_images(filename):\n",
    "    #function from Dylan\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        full_img_data = np.array(f['van_hateren_good'], dtype=np.float32)\n",
    "    return full_img_data\n",
    "\n",
    "class vanHateren:\n",
    "    def __init__(self,\n",
    "                 img_dir,\n",
    "                 patch_edge_size=None,\n",
    "                 normalize=False,\n",
    "                 rand_state=np.random.RandomState()):\n",
    "        self.images = self.extract_images(img_dir, patch_edge_size, normalize)\n",
    "\n",
    "    \"\"\"\n",
    "    adapted from Dylan Payton's code for Sparse coding here: https://github.com/dpaiton/FeedbackLCA/blob/master/data/input_data.py\n",
    "    load in van hateren dataset\n",
    "    if patch_edge_size is specified, rebuild data array to be of sequential image\n",
    "    patches.\n",
    "    if preprocess is true, subtract mean from each full-size image, and rescale image variance to 1\n",
    "    Note: in K&S2011, methods report input images' piel values were 'linear with respect to light intensity'\n",
    "    I'm not sure if this is true for the VH images we are using, and how to properly normalize for this if not.\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_images(self, filename, patch_edge_size=None, normalize=False):\n",
    "        with h5py.File(filename, \"r\") as f:\n",
    "            full_img_data = np.array(f['van_hateren_good'], dtype=np.float32)\n",
    "            if(normalize):\n",
    "                print('normalizing...')\n",
    "                full_img_data = full_img_data - np.mean(full_img_data,axis=(1,2),keepdims=True)\n",
    "                full_img_data = full_img_data/np.std(full_img_data,axis=(1,2),keepdims=True)\n",
    "            if patch_edge_size is not None:\n",
    "                print('sectioning into patches....')\n",
    "                (num_img, num_px_rows, num_px_cols) = full_img_data.shape\n",
    "                num_img_px = num_px_rows * num_px_cols\n",
    "                assert np.sqrt(num_img_px) % patch_edge_size == 0, (\"The number of image edge pixels % the patch edge size must be 0.\")\n",
    "                self.num_patches = int(num_img_px / patch_edge_size**2)\n",
    "                full_img_data = np.reshape(full_img_data, (num_img, num_img_px))\n",
    "                data = np.vstack([full_img_data[idx,...].reshape(self.num_patches, patch_edge_size, patch_edge_size) for idx in range(num_img)])\n",
    "            else:\n",
    "                data = full_img_data\n",
    "                self.num_patches = 0\n",
    "            return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "nneurons = 100\n",
    "patchsize = 16\n",
    "\n",
    "\n",
    "#noise - these Prateek is interested in changing to removed iid asumption\n",
    "noisexsigma = 0.4\n",
    "noisersigma = 2\n",
    "\n",
    "lambdaj = 0.1 #this is adjusted in order to get ravg = 1\n",
    "ravg = 1\n",
    "\n",
    "batchsize = 100\n",
    "iterations = 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing...\n",
      "sectioning into patches....\n"
     ]
    }
   ],
   "source": [
    "#full images\n",
    "#vhims = extract_images('../vanHaterenNaturalImages/VanHaterenNaturalImagesCurated.h5')\n",
    "\n",
    "#image patches (as in Karklin& Simoncelli)\n",
    "vhims = vanHateren(\n",
    "    img_dir='../vanHaterenNaturalImages/VanHaterenNaturalImagesCurated.h5',\n",
    "    normalize = True,\n",
    "    patch_edge_size=patchsize\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x124476a20>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFdCAYAAADSR9wBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFWQIS1JBhrAkFWQIS1JBhrAkFfT/AdAECcdGXDRVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1243ad630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#example image\n",
    "plt.imshow(vhims.images[400,:,:],cmap='gray', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-9c6c557f4d6f>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-9c6c557f4d6f>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    cx = x.T @ x\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#inputs & outputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, patchsize**2])\n",
    "\n",
    "#weights and reul\n",
    "W = tf.Variable(tf.zeros([patchsize**2,nneurons]))\n",
    "reluslope = tf.Variable(tf.zeros([nneurons]))\n",
    "reluoff = tf.Variable(tf.zeros([nneurons]))\n",
    "\n",
    "#b = tf.Variable(tf.zeros([nneurons]))\n",
    "\n",
    "#initialize vairaibles\n",
    "#sess.run(tf.initialize_all_variables())\n",
    "\n",
    "noisex = np.random.normal(loc=0, scale=noisexsigma**2, size=patchsize**2)\n",
    "noiser = np.random.normal(loc=0, scale=noisersigma**2, size=nneurons)\n",
    "\n",
    "# y = weights * (x + noise_x)\n",
    "# r = reluslope * sigmoid(y+reluoff)  + noise_r\n",
    "\n",
    "y = tf.matmul(tf.add(x,noisex),W)\n",
    "r = tf.add(reluslope*tf.nn.relu(y + reluoff), noiser)\n",
    "\n",
    "#objective (maximize): I(X,R)-sum_j(lambda*<r_j>)\n",
    "G = np.diag(alpha*(y > reluoff))\n",
    "cx = x.T @ x\n",
    "cnr = noiser.T @ noiser\n",
    "cnx = noisex.T @ noisex\n",
    "\n",
    "#crx = G @ W.T @ np.cov(noisex) @ W @ G+ np.cov(noiser)\n",
    "cxr = numpy.linalg.inv(cx) + W @ G * np.linalg.inv(G @ W.T @ cnx @ W @ G + cnr)@ G @ W.T\n",
    "information = mean(0.5*2 np.ln(2*np.pi*e*np.det(cxr)))\n",
    "objective =  information - sum(r)/nneurons\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(-1*objective)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n",
      "(100,)\n",
      "[[-1.62705879  0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.         -0.56170972  0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.45269314 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ..., -0.03584857  0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.19402789  0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.         -0.0539332 ]]\n"
     ]
    }
   ],
   "source": [
    "G = np.identity(nneurons)\n",
    "R = np.random.randn(nneurons)\n",
    "print(np.shape(G))\n",
    "print(np.shape(R))\n",
    "print(np.diag(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    " \n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
