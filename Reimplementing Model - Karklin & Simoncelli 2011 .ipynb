{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import h5py\n",
    "import pylab\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils.plotutils as plu\n",
    "import utils.imreadin as imr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "nneurons = 100\n",
    "patchsize = 128\n",
    "batchsize = 101\n",
    "iterations = 10\n",
    "testiterations = 100\n",
    "\n",
    "#noise - these Prateek is interested in changing to removed iid asumption\n",
    "noisexsigma = 0.4 #1e-4\n",
    "noisersigma = 2 #1e-4\n",
    "\n",
    "#to keep covariance matrix small for now\n",
    "npatchestotal =  iterations*batchsize #np.int(1e6)\n",
    "\n",
    "lambdaj = 1e-5 #this is adjusted in order to get ravg = 1\n",
    "ravg = 1\n",
    "#minact = 1e-1\n",
    "#bslfr = 1e-1\n",
    "\n",
    "learning_rate = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#full images\n",
    "#vhims = extract_images('../vanHaterenNaturalImages/VanHaterenNaturalImagesCurated.h5')\n",
    "\n",
    "#image patches (as in Karklin& Simoncelli)\n",
    "#only load in image patches if we haven't yet.\n",
    "try:\n",
    "    vhims\n",
    "except NameError:\n",
    "    print(\"Loading Van Hateren Natural Image Database...\")\n",
    "    vhims = imr.vanHateren(\n",
    "        img_dir='../vanHaterenNaturalImages/VanHaterenNaturalImagesCurated.h5',\n",
    "        normalize = True,\n",
    "        patch_edge_size=patchsize\n",
    "        )\n",
    "    print(\"Done Loading!\")    \n",
    "    #np.random.shuffle(vhims.images)\n",
    "    print(\"Done Shuffling!\")\n",
    "    \n",
    "    ##reduce images so we only hold in memory the ones we're using\n",
    "    #vhims.images = vhims.images[0:npatchestotal]\n",
    "    \n",
    "print(\"Images Loaded. Carry On!\")\n",
    "\n",
    "#code to save if i had enough hd space. i shold buy a new computer.\n",
    "#f=open('../vanHaterenNaturalImages/vhnormpatches_{}.npy'.format(patchsize),'wb')\n",
    "#np.save(f,vhims)\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.shape(vhims.images))\n",
    "plt.imshow(vhims.images[340],cmap='gray',interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#covariance parameters\n",
    "\n",
    "#global curvature of images\n",
    "try:\n",
    "    cx\n",
    "except NameError:\n",
    "    print(\"Couldn't find C_x matrix. Calculating now....\")\n",
    "    xr = vhims.images[0:npatchestotal,:,:].T.astype('float32')\n",
    "    cx = np.cov(np.reshape(xr,(patchsize**2,-1)),rowvar=True)\n",
    "print(\"C_x calculated. Shape is {}, calculated from {} patches.\".format(np.shape(cx),np.shape(xr[1,:])))\n",
    "\n",
    "#cx = np.cov(xr)\n",
    "#cx=cx/15\n",
    "#cx = np.dot(xr,xr.T)/npatchestotal - np.dot(np.mean(xr,axis=1,keepdims=True).T,np.mean(xr,axis=1,keepdims=True))\n",
    "#cx = np.eye(patchsize**2)\n",
    "#print(cx)\n",
    "#print(np.linalg.det(cx))\n",
    "#plt.pcolormesh(np.linalg.inv(cx))\n",
    "plt.xlim(0,256)\n",
    "plt.ylim(0,256)\n",
    "plt.pcolormesh(cx)\n",
    "plt.colorbar()\n",
    "\n",
    "#noise covariances\n",
    "cnx = np.eye(patchsize**2) * noisexsigma**2\n",
    "cnr = np.eye(nneurons) * noisersigma**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input image\n",
    "x = tf.placeholder(tf.float32, shape=(patchsize**2,batchsize),name='input_image')\n",
    "\n",
    "#noise\n",
    "nx = tf.placeholder(tf.float32, shape=(patchsize**2,batchsize),name='input_noise')\n",
    "nr = tf.placeholder(tf.float32, shape=(nneurons,batchsize),name='response_noise')\n",
    "\n",
    "#covariances\n",
    "cxt = tf.constant(cxnorm,dtype=tf.float32)#+0.01\n",
    "cnxt = tf.constant(cnx,dtype=tf.float32)#+0.01\n",
    "cnrt = tf.constant(cnr,dtype=tf.float32)#+0.01\n",
    "\n",
    "#weights\n",
    "w = tf.Variable(tf.random_normal(shape=(patchsize**2,nneurons),dtype=tf.float32,stddev=1),name='weights')\n",
    "#relu params - both positive\n",
    "actslope = tf.Variable(np.abs(tf.random_normal([nneurons,1],stddev=1,dtype=tf.float32)),dtype=tf.float32,name='relu_slope')\n",
    "actoffset = tf.Variable(np.abs(tf.random_normal([nneurons,1],stddev=5,dtype=tf.float32)),dtype=tf.float32,name='relu_offset')\n",
    "\n",
    "#activation function\n",
    "def af(slope,offset,y):\n",
    "    #return(1/(1+tf.exp(-1*slope*(y+offset)))) #sigmoid\n",
    "    return(tf.mul(tf.abs(slope),tf.nn.relu(tf.add(y,offset)))) #relu\n",
    "\n",
    "def af_ddy(slope,offset,y):\n",
    "    #return(slope*af(slope,offset,y)*(1-af(slope,offset,y))) #sigmoid\n",
    "    return(tf.mul(tf.cast(tf.less(offset, y),tf.float32),tf.abs(slope))) #relu\n",
    "    \n",
    "#calculate response\n",
    "w = w/tf.sqrt(tf.reduce_sum(tf.pow(w,2),axis=0))\n",
    "y = tf.transpose(tf.matmul(tf.transpose(x + nx),w))\n",
    "r = tf.add(af(actslope,actoffset,y), nr)\n",
    "indvrate = tf.reduce_mean(r,1)\n",
    "meanrate = tf.reduce_mean(indvrate)\n",
    "\n",
    "#objective function: maximize I(X,R)-sum_j(lambda*<r_j>)\n",
    "#1s for all places respose (y + offset) is greater than zero\n",
    "#mask = tf.cast(tf.less(tf.zeros((nneurons,1)),y+reluoff),tf.float32)\n",
    "#multiply response by reluslope everywhere response was greater than zero, add baseline to this.\n",
    "g = tf.matrix_diag(tf.transpose(af_ddy(actslope,actoffset,y)))\n",
    "gt = tf.transpose(g,[1,2,0])\n",
    "\n",
    "slopes = af_ddy(actslope,actoffset,y)\n",
    "\n",
    "crx = tf.matmul(cnxt,w)\n",
    "crx = tf.matmul(tf.transpose(w),crx)\n",
    "crx = tf.einsum('ijk,kl->ijl',g,crx)\n",
    "crx = tf.batch_matmul(crx,g) + cnr\n",
    "\n",
    "\n",
    "\n",
    "cxr = tf.matrix_inverse(tf.matrix_inverse(cxt) + tf.einsum('ij,kjl->kil',w,tf.einsum('ijk,kl->ijl',\n",
    "                        tf.batch_matmul(tf.batch_matmul(g,tf.matrix_inverse(crx)),g),tf.transpose(w))))\n",
    "\n",
    "\n",
    "#informion = tf.reduce_mean(0.5*tf.log1p(2*np.pi*np.exp(1)*(5)))\n",
    "det_g = tf.matrix_determinant(g)\n",
    "detcxrt = tf.matrix_determinant(cxr)\n",
    "information = -0.5*tf.log1p(2*np.pi*np.exp(1)*tf.reduce_mean(tf.matrix_determinant(cxr)))\n",
    "objective =  information - lambdaj * meanrate #/nneurons\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(-objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run it!\n",
    "#sess = tf.Session\n",
    "with tf.Session() as sess:\n",
    "    #initialize vars\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    #save evolution of system over training\n",
    "    information_evolution = []\n",
    "    objective_evolution = []\n",
    "    rate_evolution = []\n",
    "    detcxrs_evolution = []\n",
    "    slopes_evolution = []\n",
    "    \n",
    "    hist = {}\n",
    "    \n",
    "    #train over niterations\n",
    "    nits = iterations #full run\n",
    "    nits = testiterations #test run\n",
    "    \n",
    "    print('Training {} iterations...'.format(nits))\n",
    "    for ii in range(nits):\n",
    "        if(ii%(int(nits/10))==0):\n",
    "            print(str(ii)+', ',end=\"\")\n",
    "        #image = np.random.rand(patchsize**2,batchsize).astype(np.float32) #random image\n",
    "        image = np.reshape(vhims.images[ii*batchsize:(1+ii)*batchsize,:,:],(batchsize,patchsize**2)).T.astype(np.float32)\n",
    "        noise_input = np.random.normal(0,noisexsigma,[patchsize**2,batchsize]).astype(np.float32)\n",
    "        noise_response = np.random.normal(0,noisersigma,[nneurons,batchsize]).astype(np.float32)\n",
    "        hist[0] = image\n",
    "        hist[1] = noise_input\n",
    "        hist[2] = noise_response \n",
    "        \n",
    "        #train\n",
    "        #train_step.run(feed_dict={x:image, nx: noise_input, nr:noise_response})\n",
    "        sess.run(train_step, feed_dict={x:image, nx: noise_input, nr:noise_response})\n",
    "        \n",
    "        #save evolution of params\n",
    "        info = sess.run(information, feed_dict={x:image, nx: noise_input, nr:noise_response})\n",
    "        information_evolution.append(info)\n",
    "        cost = sess.run(objective, feed_dict={x:image, nx: noise_input, nr:noise_response})\n",
    "        objective_evolution.append(cost)\n",
    "        rate = sess.run(indvrate, feed_dict={x:image, nx: noise_input, nr:noise_response})\n",
    "        rate_evolution.append(rate)\n",
    "        detcxr = sess.run(detcxrt, feed_dict={x:image, nx: noise_input, nr:noise_response})\n",
    "        detcxrs_evolution.append(detcxr)\n",
    "        slopesr = sess.run(slopes, feed_dict={x:image, nx: noise_input, nr:noise_response})\n",
    "        slopes_evolution.append(slopesr)\n",
    "        \n",
    "#       if ii%iterations == 0:\n",
    "#            pass\n",
    "        \n",
    "    #print statements\n",
    "    #myweights = w.eval()\n",
    "    #print(myweights)\n",
    "    #myrlus = reluslope.eval()\n",
    "    #print(myrlus)\n",
    "    #myrluof = reluoff.e`val()\n",
    "    #print(myrluof)\n",
    "    #myrs = r.eval()\n",
    "    #print(myrs)\n",
    "    #myobjective = objective.eval()\n",
    "    #print(myobjective)\n",
    "    weights = sess.run(w, feed_dict={x:image, nx: noise_input, nr:noise_response})\n",
    "    detz = sess.run(g, feed_dict={x:image, nx: noise_input, nr:noise_response})\n",
    "    print('Done!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.subplot(3,1,1,title='Information')\n",
    "plt.plot(information_evolution)\n",
    "\n",
    "plt.subplot(3,1,2,title='Firing Rate')\n",
    "plt.plot(np.mean(rate_evolution,1))\n",
    "\n",
    "plt.subplot(3,1,3,title='Objective')\n",
    "plt.plot(objective_evolution)\n",
    "\n",
    "#plt.subplot(2,2,4,title='cxrs Determinant')\n",
    "#plt.plot(detcxrs_evolution)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wr = np.rollaxis(np.reshape(weights,(patchsize,patchsize,nneurons)),2)\n",
    "plu.display_data_tiled(wr, normalize=False, title=\"weights\", prev_fig=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(weights[:,6],(patchsize,patchsize)),interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### weights\n",
    "w = np.random.randn(patchsize**2,nneurons)\n",
    "#relu params - both positive\n",
    "actslope = np.abs(np.random.randn(nneurons,1))\n",
    "actoffset = np.abs(np.random.randn(nneurons,1))\n",
    "\n",
    "\n",
    "def sigmoid_af(slope,offset,y):\n",
    "    #return(1/(1+tf.exp(-1*slope*(y+offset))))\n",
    "    return(np.abs(slope)*((y-offset)>0))\n",
    "\n",
    "def sigmoid_af_ddy(slope,offset,y):\n",
    "    #return(slope*sigmoid_af(slope,offset,y)*(1-sigmoid_af(slope,offset,y)))\n",
    "    mask = (offset[:,0] < y.T)\n",
    "    return(mask*np.abs(slope[:,0]))\n",
    "\n",
    "\n",
    "\n",
    "#calculate response\n",
    "y = np.transpose(np.dot(np.transpose(hist[0][:,0] + hist[1][:,0]),w))\n",
    "#print(np.transpose(hist[0] + hist[1]).shape)\n",
    "#print(w.shape)\n",
    "#print(y.shape)\n",
    "r = np.add(sigmoid_af(actslope, actoffset, y), hist[2][:,0])\n",
    "rate = np.mean(r,0)\n",
    "#print(rate)\n",
    "\n",
    "#g = np.diag(np.reshape(sigmoid_af_ddy(actslope,actoffset,y),-1)+0.1) \n",
    "g = np.diag(np.reshape(sigmoid_af_ddy(actslope,actoffset,y),[nneurons]))\n",
    "\n",
    "print('g')\n",
    "print(g)\n",
    "print(np.linalg.det(g))\n",
    "print(np.trace(g))\n",
    "\n",
    "print('cxnorm')\n",
    "print(cxnorm)\n",
    "print(np.linalg.det(cxnorm))\n",
    "\n",
    "print('cnx')\n",
    "print(cnx)\n",
    "print(np.linalg.det(cnx))\n",
    "\n",
    "print('cnr')\n",
    "print(cnr)\n",
    "print(np.linalg.det(cnr))\n",
    "\n",
    "\n",
    "cxr = np.linalg.inv(np.linalg.inv(cx) + #with inverse calculated by Shariq\n",
    "#cxr =  1 * (tf.matrix_inverse(cx) + #as in paper\n",
    "                        np.dot(w, \n",
    "                        np.dot(g, \n",
    "                        np.dot(np.linalg.inv(\n",
    "                        np.dot(g,\n",
    "                        np.dot(np.transpose(w), \n",
    "                        np.dot(cnx, \n",
    "                        np.dot(w, g)))) + cnr),\n",
    "                        np.dot(g, np.transpose(w))))))\n",
    "\n",
    "print('cxr')\n",
    "print(np.linalg.det(cxr))\n",
    "print(cxr)\n",
    "\n",
    "print('gwcwg')\n",
    "pgwcwg = np.linalg.inv(np.dot(g,np.dot(w.T,np.dot(cnx,np.dot(w,g))))+cnr)\n",
    "gwcwg = np.dot(w,np.dot(g,np.dot(pgwcwg,np.dot(g,w.T))))+np.linalg.inv(cx)\n",
    "\n",
    "print(gwcwg)\n",
    "\n",
    "print(np.linalg.det(gwcwg))\n",
    "\n",
    "plt.pcolormesh(gwcwg)\n",
    "plt.colorbar()\n",
    "\n",
    "information = np.mean(0.5*np.log1p(2*np.pi*np.exp(1)*(np.linalg.det(cxr))))\n",
    "objective =  information - np.sum(lambdaj * rate)#/nneurons\n",
    "\n",
    "print(information)\n",
    "#train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(-objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(cx-np.mean(cx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
